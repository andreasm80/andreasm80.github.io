<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Loadbalancing on From 0.985mhz... to several Ghz</title>
    <link>https://blog.andreasm.io/categories/loadbalancing/</link>
    <description>Recent content in Loadbalancing on From 0.985mhz... to several Ghz</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Myself</copyright>
    <lastBuildDate>Tue, 26 Dec 2023 20:31:45 +0100</lastBuildDate><atom:link href="https://blog.andreasm.io/categories/loadbalancing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Traefik Proxy in Kubernetes</title>
      <link>https://blog.andreasm.io/2023/12/26/traefik-proxy-in-kubernetes/</link>
      <pubDate>Tue, 26 Dec 2023 20:31:45 +0100</pubDate>
      
      <guid>https://blog.andreasm.io/2023/12/26/traefik-proxy-in-kubernetes/</guid>
      <description>
        
          
            In this post I will go through how I have configured and run Traefik in my Kubernetes lab.
          
          
        
      </description>
    </item>
    
    <item>
      <title>TKGi with NSX and NSX Advanced LoadBalancer</title>
      <link>https://blog.andreasm.io/2023/11/23/tkgi-with-nsx-and-nsx-advanced-loadbalancer/</link>
      <pubDate>Thu, 23 Nov 2023 08:17:49 +0100</pubDate>
      
      <guid>https://blog.andreasm.io/2023/11/23/tkgi-with-nsx-and-nsx-advanced-loadbalancer/</guid>
      <description>
        
          
            In this post I will go through installation of TKGi, using the EPMC installer, then how to configure TKGi to use NSX Advanced LoadBalancer
          
          
        
      </description>
    </item>
    
    <item>
      <title>Tanzu Kubernetes Grid 2.2 &amp; Remote Workload Clusters</title>
      <link>https://blog.andreasm.io/2023/05/30/tanzu-kubernetes-grid-2.2-remote-workload-clusters/</link>
      <pubDate>Tue, 30 May 2023 14:54:29 +0200</pubDate>
      
      <guid>https://blog.andreasm.io/2023/05/30/tanzu-kubernetes-grid-2.2-remote-workload-clusters/</guid>
      <description>
        
          
            In this post I will quickly go through how to use a Tanzu Kubernetes Grid management cluster to deploy and manage workload clusters in edge/remote locations.
          
          
        
      </description>
    </item>
    
    <item>
      <title>AKO Explained</title>
      <link>https://blog.andreasm.io/2022/10/26/ako-explained/</link>
      <pubDate>Wed, 26 Oct 2022 12:02:39 +0200</pubDate>
      
      <guid>https://blog.andreasm.io/2022/10/26/ako-explained/</guid>
      <description>
        
          
            What is AKO? AKO is an operator which works as an ingress controller and performs Avi-specific functions in an OpenShift/Kubernetes environment with the Avi Controller. It runs as a pod in the cluster and translates the required OpenShift/Kubernetes objects to Avi objects and automates the implementation of ingresses/routes/services on the Service Engines (SE) via the Avi Controller. ref: link
How to install AKO AKO is very easy installed with Helm. Four basic steps needs to be done.
          
          
        
      </description>
    </item>
    
    <item>
      <title>GSLB With AKO &amp; AMKO - NSX Advanced LoadBalancer</title>
      <link>https://blog.andreasm.io/2022/10/23/gslb-with-ako-amko-nsx-advanced-loadbalancer/</link>
      <pubDate>Sun, 23 Oct 2022 08:22:35 +0200</pubDate>
      
      <guid>https://blog.andreasm.io/2022/10/23/gslb-with-ako-amko-nsx-advanced-loadbalancer/</guid>
      <description>
        
          
            Global Server LoadBalancing in VMware Tanzu with AMKO This post will go through how to configure AVI (NSX ALB) with GSLB in vSphere with Tanzu (TKGs) and an upstream k8s cluster in two different physical locations. I have already covered AKO in my previous posts, this post will assume knowledge of AKO (Avi Kubernetes Operator) and extend upon that with the use of AMKO (Avi Multi-Cluster Kubernetes Operator). The goal is to have the ability to scale my k8s applications between my &amp;quot;sites&amp;quot; and make them geo-redundant.
          
          
        
      </description>
    </item>
    
    <item>
      <title>We Take a Look at the AKO Crds</title>
      <link>https://blog.andreasm.io/2022/10/23/we-take-a-look-at-the-ako-crds/</link>
      <pubDate>Sun, 23 Oct 2022 08:21:52 +0200</pubDate>
      
      <guid>https://blog.andreasm.io/2022/10/23/we-take-a-look-at-the-ako-crds/</guid>
      <description>
        
          
            AKO settings: What happens if we need to to this
What happens if I need passthrough
How does AKO work
          
          
        
      </description>
    </item>
    
    <item>
      <title>Configure NSX Advanced Load Balancer (NSX-ALB) as DNS provider</title>
      <link>https://blog.andreasm.io/2021/07/12/configure-nsx-advanced-load-balancer-nsx-alb-as-dns-provider/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.andreasm.io/2021/07/12/configure-nsx-advanced-load-balancer-nsx-alb-as-dns-provider/</guid>
      <description>
        
          
            NSX ALB has a very useful feature built-in, to function as DNS server for your domains defined in your NSX-ALB environment. Meaning that all host-records will be automatically resolved by fqdn as soon as the service is created.
If you have followed my other post about how to configure the AKO (Avi Kubernetes Operator) here you are familiar with creating DNS profiles in NSX-ALB. The first step in configuring NSX-ALB as DNS provider is to configure one or more domain names in NSX-ALB.
          
          
        
      </description>
    </item>
    
    <item>
      <title>K8s Ingress with NSX Advanced Load Balancer</title>
      <link>https://blog.andreasm.io/2021/07/11/k8s-ingress-with-nsx-advanced-load-balancer/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://blog.andreasm.io/2021/07/11/k8s-ingress-with-nsx-advanced-load-balancer/</guid>
      <description>
        
          
            Abbreviations used in this article:
NSX Advanced Load Balancer = NSX-ALB K8s = Kubernetes (8 letters between the K and s in Kubernetes) SSL = Secure Sockets Layer AKO = Avi Kubernetes Operator (AVI now a VMware product called NSX Advanced Load Balancer) In one of my previous posts I wrote about how to install and configure AKO (Avi Kubernetes Operator) to use as Service type LoadBalancer.
This post will try to cover the basics of how to use NSX Advanced LoadBalancer by using AKO to handle our Ingress requests (ingress-controller).
          
          
        
      </description>
    </item>
    
    <item>
      <title>NSX Advanced LoadBalancer with Antrea on Native K8s</title>
      <link>https://blog.andreasm.io/2020/10/08/nsx-advanced-loadbalancer-with-antrea-on-native-k8s/</link>
      <pubDate>Thu, 08 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://blog.andreasm.io/2020/10/08/nsx-advanced-loadbalancer-with-antrea-on-native-k8s/</guid>
      <description>
        
          
            This post will cover the steps to bring up a Kubernetes cluster in Ubuntu, then how to install and configure Antrea as CNI and how to install and configure NSX Advanced Load Balancer to use as a servicetype Load Balancer in the k8s environment with the use of Avi Kubernetes Operator.
Abbreviations used in this post:
NSX Advanced Load Balancer = NSX ALB Avi Kubernetes Operator = AKO Kubernetes = k8s Container Network Interface = CNI Load Balancer = lb Introduction to this post When working with pods in a k8s cluster there is often the use of nodePort, clusterIP and LoadBalancer.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
